---
layout: single
title: "Recurrent Neural Network (RNN) - 2"
excerpt: "통계 기반 기법"
toc: true
toc_sticky: true
categories:
  - deep-learning
tags:
  - rnn
---


### 통계 기반 기법
시소러스 문제점을 개선하기 위해서 탄생한 것이 바로 통계 기반 기법이다. **통계 기반 기법은 특정 단어에 주목했을 때, 그 주번에 어떤 단어가 몇 번이나 등장하는지를 세어 집계하는 방법**을 사용한다. **예시와 검색 기반의 방법론이 발전되면서 만들어진 방법**이다. 그리고 **컴퓨터가 학습을 할 수 있도록 번역된 데이터를 모으는 것도 쉬운 일이 아닌데 데이터가 보통 1천만 문장 이상이 있어야 쓸만한 성능**이 나온다. 또한 **어떤 분야에 대한 것인지 그 분야에 굉장히 의존적**이다. 예를 들어, 뉴스에 대한 데이터를 학습시킨 모델을 SNS 번역에 적용하면 심각한 성능 저하가 발생한다. 각 분야마다 스타일이 달라서, 사용하는 단어들이 다르고 형식이 다르기 때문이다.


통계 기반 기법을 활용한 파이썬 예시이다.

```python
import numpy as np

def preprocess(text):
    text = text.lower()
    text = text.replace(".", " .")
    words = text.split(" ")
    
    word_to_id = {}
    id_to_word = {}
    for word in words:
        if word not in word_to_id:
            new_id = len(word_to_id)
            word_to_id[word] = new_id
            id_to_word[new_id] = word
            
    corpus = np.array([word_to_id[w]] for w in words)
    
    return corpus, word_to_id, id_to_word
```

정의된 함수를 보면, 먼저 text에 대한 전처리을 해준다. 모든 문자를 소문자로 바꿔주고 한 단어씩 잘라낸다. 그리고 두 개의 사전 자료형을 구축하고, 전처리된 단어들에 대해서 한 단어씩 id를 생성하고 구축해 놓았던 두 개의 사전에 `단어가 key이고 생성된 id가 value`, 반대로 `생성된 id가 key이고 단어가 value`의 형태로 입력한다. 그리고 나서 첫번째 사전의 전체 단어들에 대해서 id로 구성된 행렬을 만들어 사전 두 개와 행렬을 return 받는다.


```python
text = "You say goodbye and I say hello."
corpus, word_to_id, id_to_word = preprocess(text)
print("corpus :", str(corpus))
print("word_to_id :", str(word_to_id))
print("id_to_word :", str(id_to_word))
```

    corpus : [0 1 2 3 4 1 5 6]
    word_to_id : {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}
    id_to_word : {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}
    

입력된 변수에 대하여 함수를 적용시킨 결과를 보면, 각 단어들에 id가 생성이 된 것을 확인할 수 있다. 또한 'say' 라는 단어가 두 번 등장하기 때문에 corpus에도 'say'의 id인 1이 다시 나오는 것을 확인할 수 있다.


#### 분포 가설
이렇게 통계 기반 기법은 단어의 분산 표현을 이용한다. 그렇기 때문에 단어의 의미를 정확하게 파악할 수 있는 벡터 표현이 가능해진다. 그리고 우리가 색을 RGB로 나타내는 것처럼 (예: 검정(0, 0, 0)) 단어를 고정 길이의 밀집벡터로 표현할 수 있다. 이 방식은 **분포가설에 의해 고안되었는데, 단어의 의미는 주변 단어에 의해 형성이 된다고 하는 가설이다. 단어 자체에는 의미가 없고, 그 단어가 사용된 '맥락'이 의미를 형성한다고 주장한다.** 시소러스는 사람이 일일이 단어의 관계성을 설명하는 작업을 했지만, **통계 기반 기법은 다양한 말뭉치를 통해서 단어들의 앞과 뒤를 보고 맥락을 파악하는 방법이다.** *참고로 맥락이란 주목하는 단어 주변에 놓인 단어이다.* 또한 분석시에, 주변 단어를 몇 개나 포함할 것인지 맥락의 크기를 정할 수 있다. 보통 이것을 '윈도우 크기'(Window size)라고 부른다.


#### 벡터(Vector) 간 유사도
통계 기반 기법에서는 벡터 간 유사도를 측정해 주어야한다. 벡터의 내적과 유클리드 거리 등을 사용하는데, 코사인 유사도(Cosine similarity)를 자주 사용한다. 왜냐하면 간단하기도 하고 성능도 좋기 때문이다.

<center><img src="{{site.baseurl}}/assets/images/cosine-similarity.png" /></center><br>

